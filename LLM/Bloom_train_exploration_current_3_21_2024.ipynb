{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eba4f35-ed22-4de8-8124-49f100a4a593",
   "metadata": {
    "id": "7eba4f35-ed22-4de8-8124-49f100a4a593"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import BloomForCausalLM\n",
    "from transformers import BloomForTokenClassification\n",
    "from transformers import BloomForTokenClassification\n",
    "from transformers import BloomTokenizerFast\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e306dd3-50db-43f1-b7ff-67c84d318535",
   "metadata": {
    "id": "5e306dd3-50db-43f1-b7ff-67c84d318535"
   },
   "source": [
    "# Bloom for Causal Language Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8879880-3c68-450b-adb1-f7a597c2f375",
   "metadata": {
    "id": "d8879880-3c68-450b-adb1-f7a597c2f375"
   },
   "outputs": [],
   "source": [
    "tokenizer = BloomTokenizerFast.from_pretrained(\"bigscience/bloomz-560m\")\n",
    "model = BloomForCausalLM.from_pretrained(\"bigscience/bloomz-560m\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eb2324-38f7-4a8c-afca-683c8fce0cd2",
   "metadata": {
    "id": "60eb2324-38f7-4a8c-afca-683c8fce0cd2"
   },
   "outputs": [],
   "source": [
    "\n",
    "prompt = 'Given the question delimited by triple backticks ```{ Tell me about some CVEs for Trojan Horses  }```, what is the answer? Answer:'\n",
    "\n",
    "result_length = 50\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9f3fef-8dbb-47ec-99a3-61e6a6c947df",
   "metadata": {
    "id": "ed9f3fef-8dbb-47ec-99a3-61e6a6c947df"
   },
   "outputs": [],
   "source": [
    "#outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "#loss = outputs.loss\n",
    "#logits = outputs.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9511aba",
   "metadata": {},
   "source": [
    "## Attempting to Fine-Tuning Given Our Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa89c01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# Connect to the SQLite database\n",
    "conn = sqlite3.connect(\"C:/Users/Andrew/Downloads/mitre (1).sqlite\")\n",
    "\n",
    "# Execute SQL query to fetch CVE number and description\n",
    "query = \"SELECT cve_number, description FROM MITRE LIMIT 1000 OFFSET (SELECT COUNT(*) FROM MITRE) - 100000\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "\n",
    "# Convert CVE number and description to lowercase\n",
    "df['cve_number'] = df['cve_number'].str.lower()\n",
    "df['description'] = df['description'].str.lower()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8f009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a string can be decoded in UTF-8\n",
    "def is_utf8(s):\n",
    "    try:\n",
    "        s.decode('utf-8')\n",
    "        return True\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "\n",
    "# Iterate over each cell in the DataFrame\n",
    "for column in df.columns:\n",
    "    df[column] = df[column].apply(lambda x: x if is_utf8(x.encode('utf-8')) else None)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Display the DataFrame after dropping rows with unreadable text\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eec2c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "df['prompt'] =  \"Given the question delimited by triple backticks ```{\" + df[\"description\"] + \"}```, what is the answer? Answer: {\" + df[\"cve_number\"] + \"}\" \n",
    "print(df.head())\n",
    "\n",
    "df_2 = pd.DataFrame({'text': df['prompt']})\n",
    "#print(df_2['text'])\n",
    "\n",
    "result = df_2.to_json(orient=\"records\")\n",
    "print(result[0:1000])\n",
    "\n",
    "with open('result.json', 'w') as f:\n",
    "    f.write(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7377a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "from transformers import BloomTokenizerFast, BloomForCausalLM, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Loading bloomz model and tokenizer \n",
    "tokenizer = BloomTokenizerFast.from_pretrained(\"bigscience/bloomz-560m\")\n",
    "model = BloomForCausalLM.from_pretrained(\"bigscience/bloomz-560m\").to(\"cpu\")\n",
    "\n",
    "#dataset = load_dataset(\"json\", data_files=\"C:/Users/Andrew/Downloads/result.json\")\n",
    "with open(\"C:/Users/Andrew/Downloads/result.json\", \"r\") as file:\n",
    "    dataset = json.load(file)\n",
    "\n",
    "print(json.dumps(dataset, indent =2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a997613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data for training\n",
    "dataset = load_dataset(\"json\", data_files=\"C:/Users/Andrew/result.json\")\n",
    "\n",
    "def prepare_train_data(data):\n",
    "    # prompt + completion\n",
    "    text_input = data['text']\n",
    "    # tokenize the input (prompt + completion) text\n",
    "    max_length = 1500\n",
    "    tokenized_input = tokenizer(text_input, return_tensors='pt', padding='max_length', max_length=max_length)\n",
    "    # generative models: labels are the same as the input\n",
    "    tokenized_input['labels'] = tokenized_input['input_ids']\n",
    "    return tokenized_input\n",
    "\n",
    "train_dataset = dataset['train'].map(prepare_train_data, \n",
    "                                     batched=True, \n",
    "                                     remove_columns=[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3d37b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Set CUDA memory management options\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_merge_size=8,max_split_size_mb=8\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c165f550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    'Purdue-bloom-560m',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    num_train_epochs=1,\n",
    "    fp16=True,\n",
    "    optim=\"adamw_torch\",\n",
    "    gradient_checkpointing=True,\n",
    "    gradient_accumulation_steps=1\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_dataset\n",
    ")\n",
    "\n",
    "print(trainer)\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0b436f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import BloomTokenizerFast, BloomForCausalLM\n",
    "\n",
    "tokenizer = BloomTokenizerFast.from_pretrained(\"bigscience/bloomz-560m\")\n",
    "model = BloomForCausalLM.from_pretrained(\"Purdue-bloom-560m\",\n",
    "                                          low_cpu_mem_usage=True).to(\"cpu\")\n",
    "prompt = 'Given the question delimited by triple backticks ```{What is the CVE number for a denial of service vulnerability}```, what is the answer? Answer:'\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer, do_sample=False)\n",
    "result = generator(prompt, max_length=45)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0756125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import BloomTokenizerFast, BloomForCausalLM\n",
    "\n",
    "tokenizer = BloomTokenizerFast.from_pretrained(\"bigscience/bloomz-560m\")\n",
    "model = BloomForCausalLM.from_pretrained(\"bigscience/bloomz-560m\",\n",
    "                                          low_cpu_mem_usage=True).to(\"cpu\")\n",
    "prompt = 'Given the question delimited by triple backticks ```{What is the CVE number for a denial of service vulnerability}```, what is the answer? Answer:'\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer, do_sample=False)\n",
    "result = generator(prompt, max_length=45)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5a0f50",
   "metadata": {},
   "source": [
    "# Pseudo SQL RAG Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b517607a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Andrew\\anaconda3\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import HumanMessagePromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import BloomForCausalLM\n",
    "from transformers import BloomForTokenClassification\n",
    "from transformers import BloomForTokenClassification\n",
    "from transformers import BloomTokenizerFast\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "735da7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">pyodbc</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 #Add your own SQL Server IP address, PORT, UID, PWD and Database</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 3 conn = pyodbc.connect(                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">'DRIVER={PostgreSQL Unicode};SERVER=localhost;PORT=5432;DATABASE=postgres;UID=postgr</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>cur = conn.cursor()                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OperationalError: </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'08001'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'[08001] connection to server at \"localhost\" (::1), port 5432 failed: Connection </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">refused (0x0000274D/10061)\\n\\tIs the server running on that host and accepting TCP/IP connections?\\nconnection to </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">server at \"localhost\" (127.0.0.1), port 5432 failed: Connection refused (0x0000274D/10061)\\n\\tIs the server running</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">on that host and accepting TCP/IP connections?\\n (101) (SQLDriverConnect)'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m3\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 1 \u001b[0m\u001b[94mimport\u001b[0m \u001b[4;96mpyodbc\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 2 \u001b[0m\u001b[2m#Add your own SQL Server IP address, PORT, UID, PWD and Database\u001b[0m                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 3 conn = pyodbc.connect(                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 4 \u001b[0m\u001b[2m│   \u001b[0m\u001b[33m'\u001b[0m\u001b[33mDRIVER=\u001b[0m\u001b[33m{\u001b[0m\u001b[33mPostgreSQL Unicode};SERVER=localhost;PORT=5432;DATABASE=postgres;UID=postgr\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 5 \u001b[0mcur = conn.cursor()                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 6 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOperationalError: \u001b[0m\u001b[1m(\u001b[0m\u001b[32m'08001'\u001b[0m, \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m08001\u001b[0m\u001b[32m]\u001b[0m\u001b[32m connection to server at \"localhost\" \u001b[0m\u001b[32m(\u001b[0m\u001b[32m::1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, port 5432 failed: Connection \u001b[0m\n",
       "\u001b[32mrefused \u001b[0m\u001b[32m(\u001b[0m\u001b[32m0x0000274D/10061\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\tIs the server running on that host and accepting TCP/IP connections?\\nconnection to \u001b[0m\n",
       "\u001b[32mserver at \"localhost\" \u001b[0m\u001b[32m(\u001b[0m\u001b[32m127.0.0.1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m, port 5432 failed: Connection refused \u001b[0m\u001b[32m(\u001b[0m\u001b[32m0x0000274D/10061\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\n\\tIs the server running\u001b[0m\n",
       "\u001b[32mon that host and accepting TCP/IP connections?\\n \u001b[0m\u001b[32m(\u001b[0m\u001b[32m101\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \u001b[0m\u001b[32m(\u001b[0m\u001b[32mSQLDriverConnect\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyodbc\n",
    "#Add your own SQL Server IP address, PORT, UID, PWD and Database\n",
    "conn = pyodbc.connect(\n",
    "    'DRIVER={PostgreSQL Unicode};SERVER=localhost;PORT=5432;DATABASE=postgres;UID=postgres;PWD=mysecretpassword', autocommit=True)\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Update rows with empty attributes in Vulnerabilities table\n",
    "cur.execute(\"UPDATE Vulnerabilities SET vulnerability_id = 'None' WHERE vulnerability_id = ''\")\n",
    "cur.execute(\"UPDATE Vulnerabilities SET description = 'None' WHERE description = ''\")\n",
    "cur.execute(\"UPDATE Vulnerabilities SET severity = 'None' WHERE severity = ''\")\n",
    "cur.execute(\"UPDATE Vulnerabilities SET required_action = 'None' WHERE required_action = ''\")\n",
    "\n",
    "# Update rows with empty attributes in AffectedProducts table\n",
    "cur.execute(\"UPDATE AffectedProducts SET vulnerability_id = 'None' WHERE vulnerability_id = ''\")\n",
    "cur.execute(\"UPDATE AffectedProducts SET product_name = 'None' WHERE product_name = ''\")\n",
    "cur.execute(\"UPDATE AffectedProducts SET version = 'None' WHERE version = ''\")\n",
    "\n",
    "# Update rows with empty attributes in ReferenceData table\n",
    "cur.execute(\"UPDATE ReferenceData SET vulnerability_id = 'None' WHERE vulnerability_id = ''\")\n",
    "cur.execute(\"UPDATE ReferenceData SET url = 'None' WHERE url = ''\")\n",
    "cur.execute(\"UPDATE ReferenceData SET description = 'None' WHERE description = ''\")\n",
    "\n",
    "cur.execute(\"ALTER TABLE Vulnerabilities ALTER COLUMN published_date TYPE TEXT\")\n",
    "#cur.execute(\"UPDATE Vulnerabilities SET published_date = TO_CHAR(published_date, 'YYYY-MM-DD') WHERE published_date IS NOT NULL\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e255584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('CVE-2018-15133', 'Laravel Framework contains a deserialization of untrusted data vulnerability, allowing for remote command execution. This vulnerability may only be exploited if a malicious user has accessed the application encryption key (APP_KEY environment variable).', '2024-01-16', '6.8', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2020-3259', 'Cisco Adaptive Security Appliance (ASA) and Firepower Threat Defense (FTD) contain an information disclosure vulnerability. An attacker could retrieve memory contents on an affected device, which could lead to the disclosure of confidential information due to a buffer tracking issue when the software parses invalid URLs that are requested from the web services interface. This vulnerability affects only specific AnyConnect and WebVPN configurations.', '2024-02-15', '5.0', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2023-7101', 'Spreadsheet::ParseExcel contains a remote code execution vulnerability due to passing unvalidated input from a file into a string-type “eval”. Specifically, the issue stems from the evaluation of Number format strings within the Excel parsing logic.', '2024-01-02', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2023-7024', 'Google Chromium WebRTC, an open-source project providing web browsers with real-time communication, contains a heap buffer overflow vulnerability that allows a remote attacker to potentially exploit heap corruption via a crafted HTML page. This vulnerability could impact web browsers using WebRTC, including but not limited to Google Chrome.', '2024-01-02', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2023-23752', 'Joomla! contains an improper access control vulnerability that allows unauthorized access to webservice endpoints.', '2024-01-08', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2016-20017', 'D-Link DSL-2750B devices contain a command injection vulnerability that allows remote, unauthenticated command injection via the login.cgi cli parameter.', '2024-01-08', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2023-41990', 'Apple iOS, iPadOS, macOS, tvOS, and watchOS contain an unspecified vulnerability that allows for code execution when processing a font file.', '2024-01-08', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2023-27524', 'Apache Superset contains an insecure default initialization of a resource vulnerability that allows an attacker to authenticate and access unauthorized resources on installations that have not altered the default configured SECRET_KEY according to installation instructions.', '2024-01-08', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2023-29300', 'Adobe ColdFusion contains a deserialization of untrusted data vulnerability that allows for code execution.', '2024-01-08', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2023-38203', 'Adobe ColdFusion contains a deserialization of untrusted data vulnerability that allows for code execution.', '2024-01-08', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2023-29357', 'Microsoft SharePoint Server contains an unspecified vulnerability that allows an unauthenticated attacker, who has gained access to spoofed JWT authentication tokens, to use them for executing a network attack. This attack bypasses authentication, enabling the attacker to gain administrator privileges.', '2024-01-10', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2023-46805', 'Ivanti Connect Secure (ICS, formerly known as Pulse Connect Secure) and Ivanti Policy Secure gateways contain an authentication bypass vulnerability in the web component that allows an attacker to access restricted resources by bypassing control checks. This vulnerability can be leveraged in conjunction with CVE-2024-21887, a command injection vulnerability.', '2024-01-10', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2024-21887', 'Ivanti Connect Secure (ICS, formerly known as Pulse Connect Secure) and Ivanti Policy Secure contain a command injection vulnerability in the web components of these products, which can allow an authenticated administrator to send crafted requests to execute code on affected appliances. This vulnerability can be leveraged in conjunction with CVE-2023-46805, an authenticated bypass issue.', '2024-01-10', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2024-0519', 'Google Chromium V8 Engine contains an out-of-bounds memory access vulnerability that allows a remote attacker to potentially exploit heap corruption via a crafted HTML page. This vulnerability could affect multiple web browsers that utilize Chromium, including, but not limited to, Google Chrome, Microsoft Edge, and Opera.', '2024-01-17', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2023-6549', 'Citrix NetScaler ADC and NetScaler Gateway contain a buffer overflow vulnerability that allows for a denial-of-service when configured as a Gateway (VPN virtual server, ICA Proxy, CVPN, RDP Proxy) or AAA virtual server.', '2024-01-17', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2023-6548', 'Citrix NetScaler ADC and NetScaler Gateway contain a code injection vulnerability that allows for authenticated remote code execution on the management interface with access to NSIP, CLIP, or SNIP.', '2024-01-17', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2023-35082', 'Ivanti Endpoint Manager Mobile (EPMM) and MobileIron Core contain an authentication bypass vulnerability that allows unauthorized users to access restricted functionality or resources of the application.', '2024-01-18', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2023-34048', 'VMware vCenter Server contains an out-of-bounds write vulnerability in the implementation of the DCERPC protocol that allows an attacker to conduct remote code execution.', '2024-01-22', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2024-23222', 'Apple iOS, iPadOS, macOS, tvOS, and Safari WebKit contain a type confusion vulnerability that leads to code execution when processing maliciously crafted web content.', '2024-01-23', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2023-22527', 'Atlassian Confluence Data Center and Server contain an unauthenticated OGNL template injection vulnerability that can lead to remote code execution.', '2024-01-24', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2022-48618', 'Apple iOS, iPadOS, macOS, tvOS, and watchOS contain a time-of-check/time-of-use (TOCTOU) memory corruption vulnerability that allows an attacker with read and write capabilities to bypass Pointer Authentication.', '2024-01-31', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2024-21893', 'Ivanti Connect Secure (ICS, formerly known as Pulse Connect Secure), Ivanti Policy Secure, and Ivanti Neurons contain a server-side request forgery (SSRF) vulnerability in the SAML component that allows an attacker to access certain restricted resources without authentication.', '2024-01-31', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2023-4762', 'Google Chromium V8 contains a type confusion vulnerability that allows a remote attacker to execute code via a crafted HTML page. This vulnerability could affect multiple web browsers that utilize Chromium, including, but not limited to, Google Chrome, Microsoft Edge, and Opera.', '2024-02-06', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2024-21762', 'Fortinet FortiOS contains an out-of-bound write vulnerability that allows a remote unauthenticated attacker to execute code or commands via specially crafted HTTP requests.', '2024-02-09', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2023-43770', 'Roundcube Webmail contains a persistent cross-site scripting (XSS) vulnerability that can lead to information disclosure via malicious link references in plain/text messages.', '2024-02-12', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2024-21412', 'Microsoft Windows Internet Shortcut Files contains an unspecified vulnerability that allows for a security feature bypass.', '2024-02-13', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2024-21351', 'Microsoft Windows SmartScreen contains a security feature bypass vulnerability that allows an attacker to bypass the SmartScreen user experience and inject code to potentially gain code execution, which could lead to some data exposure, lack of system availability, or both.', '2024-02-13', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2024-21410', 'Microsoft Exchange Server contains an unspecified vulnerability that allows for privilege escalation.', '2024-02-15', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2024-1709', 'ConnectWise ScreenConnect contains an authentication bypass vulnerability that allows an attacker with network access to the management interface to create a new, administrator-level account on affected devices.', '2024-02-22', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2023-29360', 'Microsoft Streaming Service contains an untrusted pointer dereference vulnerability that allows for privilege escalation, enabling a local attacker to gain SYSTEM privileges.', '2024-02-29', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "('CVE-2024-21338', 'Microsoft Windows Kernel contains an exposed IOCTL with insufficient access control vulnerability within the IOCTL (input and output control) dispatcher in appid.sys that allows a local attacker to achieve privilege escalation.', '2024-03-04', 'None', 'Apply mitigations per vendor instructions or discontinue use of the product if mitigations are unavailable.')\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyodbc\n",
    "#Add your own SQL Server IP address, PORT, UID, PWD and Database\n",
    "conn = pyodbc.connect(\n",
    "    'DRIVER={PostgreSQL Unicode};SERVER=localhost;PORT=5432;DATABASE=postgres;UID=postgres;PWD=mysecretpassword', autocommit=True)\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute(\"SELECT * FROM Vulnerabilities WHERE published_date > '2024-01-01' LIMIT 100\")\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9287ddc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "db = SQLDatabase.from_uri(\"postgresql://postgres:mysecretpassword@localhost\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "988a5f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#tokenizer = BloomTokenizerFast.from_pretrained(\"bigscience/bloomz-560m\")\n",
    "#model = BloomForCausalLM.from_pretrained(\"bigscience/bloomz-560m\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb76626",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329a2d7b6eef4371bb9901e2bb514f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain_experimental.sql import SQLDatabaseSequentialChain\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from huggingface_hub import notebook_login\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    " \n",
    "#from transformers import BloomTokenizerFast\n",
    "#tokenizer = BloomTokenizerFast.from_pretrained(\"bigscience/bloom\", add_prefix_space=True, is_split_into_words=True)\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "token = \"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\"\n",
    "\n",
    "\n",
    "#CHANGE THE BELOW LINE WITH WHATEVER MODEL YOU FIND ON HUGGINGFACE OR WHEREVER\n",
    "model_id=\"meta-llama/Llama-2-7b-chat-hf\"  # \"bigscience/bloomz-560m\"\n",
    "\n",
    "#use_fast=False comes from https://github.com/langchain-ai/langchain/discussions/18192 attempting to fix an error (Rust vs. Python)\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_id, use_fast=False)\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=100\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "#instruct_pipeline = pipeline(model=\"meta-llama/Llama-2-70b-chat-hf\",token = token, trust_remote_code=True, use_auth_token=True, use_fast=False, device_map=\"auto\", return_full_text=True, do_sample=False, max_new_tokens=128)\n",
    "#hf_pipe = HuggingFacePipeline(pipeline=instruct_pipeline)\n",
    "#chain = SQLDatabaseSequentialChain.from_llm(llm=hf_pipe, db=db, verbose=True)\n",
    "chain = create_sql_query_chain(llm=llm, db=db)\n",
    "chain.invoke({\"question\": \"How many new CVES since January of 2024?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df70bde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e9476aa4a043c0bb11483d58dd804a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4b8b84a46c43e8806feebb1df4cf92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">12</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 #tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>12 instruct_pipeline = pipeline(model=<span style=\"color: #808000; text-decoration-color: #808000\">\"meta-llama/Llama-2-7b-chat-hf\"</span>, use_fast=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>, trus    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span>hf_pipe = HuggingFacePipeline(pipeline=instruct_pipeline)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 #chain = SQLDatabaseSequentialChain.from_llm(llm=hf_pipe, db=db, verbose=True)</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span>chain = create_sql_query_chain(llm=hf_pipe, db=db)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\Andrew\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">779</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pipeline</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">776 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Forced if framework already defined, inferred if it's None</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">777 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Will load the correct model if possible</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">778 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>model_classes = {<span style=\"color: #808000; text-decoration-color: #808000\">\"tf\"</span>: targeted_task[<span style=\"color: #808000; text-decoration-color: #808000\">\"tf\"</span>], <span style=\"color: #808000; text-decoration-color: #808000\">\"pt\"</span>: targeted_task[<span style=\"color: #808000; text-decoration-color: #808000\">\"pt\"</span>]}                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>779 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>framework, model = infer_framework_load_model(                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">780 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>model,                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">781 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>model_classes=model_classes,                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">782 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>config=config,                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\Andrew\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">271</span> in                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">infer_framework_load_model</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 268 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">continue</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 269 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 270 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(model, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>):                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 271 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">ValueError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Could not load model {</span>model<span style=\"color: #808000; text-decoration-color: #808000\">} with any of the following cl</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 272 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 273 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>framework = <span style=\"color: #808000; text-decoration-color: #808000\">\"tf\"</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"keras.engine.training.Model\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">str</span>(inspect.getmro(model.<span style=\"color: #ff0000; text-decoration-color: #ff0000\">__clas</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 274 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> framework, model                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ValueError: </span>Could not load model meta-llama/Llama-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>-7b-chat-hf with any of the following classes: <span style=\"font-weight: bold\">(&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'transformers.models.auto.modeling_auto.AutoModelForCausalLM'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;, &lt;class </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'transformers.models.auto.modeling_tf_auto.TFAutoModelForCausalLM'</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;, &lt;class </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'transformers.models.llama.modeling_llama.LlamaForCausalLM'</span><span style=\"font-weight: bold\">&gt;)</span>.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m12\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m#tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")\u001b[0m                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m12 instruct_pipeline = pipeline(model=\u001b[33m\"\u001b[0m\u001b[33mmeta-llama/Llama-2-7b-chat-hf\u001b[0m\u001b[33m\"\u001b[0m, use_fast=\u001b[94mFalse\u001b[0m, trus    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0mhf_pipe = HuggingFacePipeline(pipeline=instruct_pipeline)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m#chain = SQLDatabaseSequentialChain.from_llm(llm=hf_pipe, db=db, verbose=True)\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0mchain = create_sql_query_chain(llm=hf_pipe, db=db)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\Andrew\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\__init__.py\u001b[0m:\u001b[94m779\u001b[0m in \u001b[92mpipeline\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m776 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Forced if framework already defined, inferred if it's None\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m777 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Will load the correct model if possible\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m778 \u001b[0m\u001b[2m│   \u001b[0mmodel_classes = {\u001b[33m\"\u001b[0m\u001b[33mtf\u001b[0m\u001b[33m\"\u001b[0m: targeted_task[\u001b[33m\"\u001b[0m\u001b[33mtf\u001b[0m\u001b[33m\"\u001b[0m], \u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m: targeted_task[\u001b[33m\"\u001b[0m\u001b[33mpt\u001b[0m\u001b[33m\"\u001b[0m]}                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m779 \u001b[2m│   \u001b[0mframework, model = infer_framework_load_model(                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m780 \u001b[0m\u001b[2m│   │   \u001b[0mmodel,                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m781 \u001b[0m\u001b[2m│   │   \u001b[0mmodel_classes=model_classes,                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m782 \u001b[0m\u001b[2m│   │   \u001b[0mconfig=config,                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\Andrew\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py\u001b[0m:\u001b[94m271\u001b[0m in                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92minfer_framework_load_model\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 268 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mcontinue\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 269 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 270 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(model, \u001b[96mstr\u001b[0m):                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 271 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mValueError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mCould not load model \u001b[0m\u001b[33m{\u001b[0mmodel\u001b[33m}\u001b[0m\u001b[33m with any of the following cl\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 272 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 273 \u001b[0m\u001b[2m│   \u001b[0mframework = \u001b[33m\"\u001b[0m\u001b[33mtf\u001b[0m\u001b[33m\"\u001b[0m \u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mkeras.engine.training.Model\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m \u001b[96mstr\u001b[0m(inspect.getmro(model.\u001b[91m__clas\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 274 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m framework, model                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mValueError: \u001b[0mCould not load model meta-llama/Llama-\u001b[1;36m2\u001b[0m-7b-chat-hf with any of the following classes: \u001b[1m(\u001b[0m\u001b[1m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\n",
       "\u001b[32m'transformers.models.auto.modeling_auto.AutoModelForCausalLM'\u001b[0m\u001b[39m>, <class \u001b[0m\n",
       "\u001b[32m'transformers.models.auto.modeling_tf_auto.TFAutoModelForCausalLM'\u001b[0m\u001b[39m>, <class \u001b[0m\n",
       "\u001b[32m'transformers.models.llama.modeling_llama.LlamaForCausalLM'\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain_experimental.sql import SQLDatabaseSequentialChain\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "\n",
    "\n",
    "instruct_pipeline = pipeline(model=\"meta-llama/Llama-2-7b-chat-hf\", use_fast=False, trust_remote_code=True, device_map=\"auto\", return_full_text=True, do_sample=False, max_new_tokens=128)\n",
    "hf_pipe = HuggingFacePipeline(pipeline=instruct_pipeline)\n",
    "#chain = SQLDatabaseSequentialChain.from_llm(llm=hf_pipe, db=db, verbose=True)\n",
    "chain = create_sql_query_chain(llm=hf_pipe, db=db)\n",
    "chain.invoke({\"question\":\"How many new CVES since January of 2024?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e3b7acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\andrew\\anaconda3\\lib\\site-packages (0.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\andrew\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\andrew\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\andrew\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\andrew\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\andrew\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\andrew\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\andrew\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\andrew\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\andrew\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\andrew\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python-headless (c:\\users\\andrew\\appdata\\roaming\\python\\python310\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -illow (c:\\users\\andrew\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7215a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "bloomex_nb.ipynb",
   "provenance": []
  },
  "environment": {
   "kernel": "venv",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
